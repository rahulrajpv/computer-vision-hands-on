{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TRAINING THE MODEL - LBP FACIAL EMOTION**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOADING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Haar cascade file for face detection\n",
    "face_cascade = cv2.CascadeClassifier(r'D:\\MTECH\\PROJECT\\DM\\SECRET\\CASCADE\\haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "# Path to the dataset directory\n",
    "dataset_dir = r'C:\\Users\\rahul\\Downloads\\class-20230604T115655Z-001\\class'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIST EMOTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of emotions\n",
    "emotions = ['angerH', 'angerL', 'happyH', 'happyL', 'sadH', 'sadL', 'surprise']\n",
    "\n",
    "\n",
    "# Number of orthogonal vectors to keep\n",
    "num_vectors = 40\n",
    "\n",
    "# List to store images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ITERATE OVER IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing angerH: 100%|██████████| 1898/1898 [00:02<00:00, 791.49it/s]\n",
      "Processing angerL: 100%|██████████| 1098/1098 [00:01<00:00, 849.77it/s]\n",
      "Processing happyH: 100%|██████████| 1321/1321 [00:02<00:00, 636.88it/s]\n",
      "Processing happyL: 100%|██████████| 1107/1107 [00:01<00:00, 738.31it/s]\n",
      "Processing sadH: 100%|██████████| 1224/1224 [00:01<00:00, 885.35it/s]\n",
      "Processing sadL: 100%|██████████| 1152/1152 [00:01<00:00, 769.36it/s]\n",
      "Processing surprise: 100%|██████████| 885/885 [00:01<00:00, 858.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the images in the dataset\n",
    "for emotion in emotions:\n",
    "    emotion_dir = os.path.join(dataset_dir, emotion)\n",
    "    image_files = os.listdir(emotion_dir)\n",
    "\n",
    "    for image_file in tqdm(image_files, desc=f'Processing {emotion}'):\n",
    "        image_path = os.path.join(emotion_dir, image_file)\n",
    "\n",
    "        # Load the input image\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Convert the image to grayscale\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces in the grayscale image\n",
    "        faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.5, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        # Iterate over the detected faces\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Extract the face region\n",
    "            face = gray_image[y:y + h, x:x + w]\n",
    "\n",
    "            # Resize the face image to 32x32 pixels\n",
    "            resized_face = cv2.resize(face, (32, 32), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            # Normalize the pixel values between 0 and 1\n",
    "            normalized_face = resized_face / 255.0\n",
    "\n",
    "            # Calculate LBP (Local Binary Patterns) values\n",
    "            lbp = local_binary_pattern(resized_face, 8, 1, method='uniform')\n",
    "\n",
    "            # Resize the LBP image to match the size of the normalized face image\n",
    "            resized_lbp = cv2.resize(lbp, (32, 32), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            # Flatten the normalized face and resized LBP images\n",
    "            flattened_face = normalized_face.flatten()\n",
    "            flattened_lbp = resized_lbp.flatten()\n",
    "\n",
    "            # Concatenate the flattened face and LBP as the combined feature\n",
    "            combined_feature = np.concatenate([flattened_face, flattened_lbp])\n",
    "\n",
    "            # Check dimensions\n",
    "            if combined_feature.shape[0] != 32 * 32 * 2:\n",
    "                print(f\"Combined feature size mismatch for {image_file}: {combined_feature.shape[0]}\")\n",
    "\n",
    "            # Append the combined feature and label to the images and labels lists\n",
    "            images.append(combined_feature)\n",
    "            labels.append(emotion)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert images and labels to NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert images and labels to NumPy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode emotion labels to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode emotion labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "    images, encoded_labels, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the input images for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the input images for CNN\n",
    "train_images = train_images.reshape(-1, 32, 32, 2)\n",
    "test_images = test_images.reshape(-1, 32, 32, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the CNN model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the CNN model architecture\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 2)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(len(emotions), activation='softmax'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "120/120 [==============================] - 4s 23ms/step - loss: 1.9063 - accuracy: 0.2218\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 1.6916 - accuracy: 0.3570\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 1.2225 - accuracy: 0.5663\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.7419 - accuracy: 0.7641\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.3482 - accuracy: 0.9066\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.1447 - accuracy: 0.9669\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.0475 - accuracy: 0.9953\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0142 - accuracy: 0.9997\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.0036 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1878db2f5b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=32, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACCURACY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1434 - accuracy: 0.9771\n",
      "Test Loss: 0.1433616280555725\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the testing set\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(\"Test Loss:\", test_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9770594239234924\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSIFICATION REPORT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict emotions for the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict emotions for the testing set\n",
    "predicted_labels = model.predict(test_images)\n",
    "predicted_labels = np.argmax(predicted_labels, axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the predicted labels back to original emotion labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the predicted labels back to original emotion labels\n",
    "predicted_emotions = label_encoder.inverse_transform(predicted_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      angerH       0.99      0.97      0.98       244\n",
      "      angerL       0.95      0.98      0.97       115\n",
      "      happyH       0.98      0.98      0.98       170\n",
      "      happyL       0.98      1.00      0.99       117\n",
      "        sadH       0.98      0.97      0.97       115\n",
      "        sadL       0.96      1.00      0.98       107\n",
      "    surprise       0.98      0.96      0.97        91\n",
      "\n",
      "    accuracy                           0.98       959\n",
      "   macro avg       0.97      0.98      0.98       959\n",
      "weighted avg       0.98      0.98      0.98       959\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate classification report\n",
    "unique_labels = label_encoder.inverse_transform(np.unique(test_labels))\n",
    "report = classification_report(test_labels, predicted_labels, target_names=unique_labels)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **SAVE THE MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('BEST_MODEL.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
