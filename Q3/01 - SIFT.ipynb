{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94d1700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ededddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "path = os.path.join(r\"C:\\Users\\reema\\Downloads\\img.jpg\")\n",
    "img = cv2.imread(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a703d675",
   "metadata": {},
   "source": [
    "# SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59f468f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scale factor\n",
    "scale_factor = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1049519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the image\n",
    "scaled_img = cv2.resize(img, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d0749f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SIFT detector\n",
    "sift = cv2.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "beaaab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect keypoints and compute descriptors\n",
    "kp1, des1 = sift.detectAndCompute(img, None)\n",
    "kp2, des2 = sift.detectAndCompute(scaled_img, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f1c948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BFMatcher with default params\n",
    "bf = cv2.BFMatcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03297c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match descriptors\n",
    "matches = bf.knnMatch(des1, des2, k=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c94d039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply ratio test\n",
    "good_matches = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.50 * n.distance:\n",
    "        good_matches.append(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3b60fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw matches\n",
    "matching_img = cv2.drawMatches(img, kp1, scaled_img, kp2, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d4af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the result\n",
    "cv2.imshow('Matching Result', matching_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2657ad",
   "metadata": {},
   "source": [
    "# Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c6a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rotation angle in degrees\n",
    "angle = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5b4eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rotation matrix\n",
    "rotation_matrix = cv2.getRotationMatrix2D((img.shape[1]/2, img.shape[0]/2), angle, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dda7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply rotation to image\n",
    "rotated_img = cv2.warpAffine(img, rotation_matrix, (img.shape[1], img.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abf1dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract SIFT keypoints and descriptors from original and rotated images\n",
    "sift = cv2.SIFT_create()\n",
    "keypoints1, descriptors1 = sift.detectAndCompute(img, None)\n",
    "keypoints2, descriptors2 = sift.detectAndCompute(rotated_img, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fb2d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display original and rotated images with keypoints\n",
    "img_with_keypoints1 = cv2.drawKeypoints(img, keypoints1, None)\n",
    "img_with_keypoints2 = cv2.drawKeypoints(rotated_img, keypoints2, None)\n",
    "cv2.imshow(\"Original Image with Keypoints\", img_with_keypoints1)\n",
    "cv2.imshow(\"Rotated Image with Keypoints\", img_with_keypoints2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c89557",
   "metadata": {},
   "source": [
    "# Affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f6452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SIFT detector\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Find keypoints and descriptors\n",
    "kp, des = sift.detectAndCompute(img, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4646e9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the affine transformation matrix\n",
    "theta = np.radians(45)\n",
    "scale = 1.0\n",
    "tx, ty = 100, -50\n",
    "\n",
    "M = np.array([\n",
    "    [scale * np.cos(theta), -scale * np.sin(theta), tx],\n",
    "    [scale * np.sin(theta), scale * np.cos(theta), ty]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69c9761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the affine transformation\n",
    "img_affine = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05de4774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find keypoints and descriptors in the transformed image\n",
    "kp_affine, des_affine = sift.detectAndCompute(img_affine, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a426da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw keypoints on the images\n",
    "img_kp = cv2.drawKeypoints(img, kp, None)\n",
    "img_affine_kp = cv2.drawKeypoints(img_affine, kp_affine, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21aca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the images\n",
    "cv2.imshow('Original', img_kp)\n",
    "cv2.imshow('Affine Transformation', img_affine_kp)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d59549",
   "metadata": {},
   "source": [
    "# Perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15cad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the four corners of the original image\n",
    "pts1 = np.float32([[0, 0], [0, img.shape[0]-1], [img.shape[1]-1, img.shape[0]-1], [img.shape[1]-1, 0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60366551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the four corners of the desired output image\n",
    "pts2 = np.float32([[0, 0], [0, 400], [400, 400], [400, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdd13c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the perspective transform matrix\n",
    "M = cv2.getPerspectiveTransform(pts1, pts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34efc83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the perspective transform to the original image\n",
    "perspective_img = cv2.warpPerspective(img, M, (400, 400))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12eb01c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract SIFT keypoints and descriptors from original and transformed images\n",
    "sift = cv2.SIFT_create()\n",
    "keypoints1, descriptors1 = sift.detectAndCompute(img, None)\n",
    "keypoints2, descriptors2 = sift.detectAndCompute(perspective_img, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20f7d8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a brute-force matcher to find matches between descriptors\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.match(descriptors1, descriptors2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b4adee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter matches by distance threshold\n",
    "threshold = 0.6 * np.max([m.distance for m in matches])\n",
    "good_matches = [m for m in matches if m.distance < threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cba41939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw matching lines on a new image\n",
    "match_img = cv2.drawMatches(img, keypoints1, perspective_img, keypoints2, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e455674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image with matching lines\n",
    "cv2.imshow(\"Matches\", match_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7116ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
